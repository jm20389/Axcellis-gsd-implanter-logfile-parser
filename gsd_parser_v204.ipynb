{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSD LOGIFILE PARSER\n",
    "## Python parser to collect IDL data from GSD Ion implanters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Program set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Load required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Look for configuration files\n",
    "\n",
    "Attempts to load the configuration files \"gsd_config_01.txt\" & \"gsd_config_02.txt\", if present in the .py application directory. This is to select the variables (columns) that will be captured during the parsing. Should these files not be present, a default set of variables will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config file was found. Loading default capture settings.\n",
      "No config file was found. Loading default capture settings.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "     with open('gsd_config_01.txt') as gsd_config_01:\n",
    "         gsd_config_01 = gsd_config_01.read()\n",
    "         print('gsd_config_01.txt file was found. Loading custom capture settings.')\n",
    "         variables = gsd_config_01.split('\\n')\n",
    "         variables = [i.strip() for i in variables]\n",
    "\n",
    "except:\n",
    "    \n",
    "    print('No config file was found. Loading default capture settings.')\n",
    "               \n",
    "    variables = ['Date',\n",
    "    'Time',\n",
    "    'Machine ID',\n",
    "    'SW Version', \n",
    "    'Wafer size',   \n",
    "    'Beam Height',      \n",
    "    'Beam Height Offset',   \n",
    "    'Estimated time',\n",
    "    'Actual time',                             \n",
    "    'Interruptions',      \n",
    "    'Particle count',        \n",
    "    'Snapshot count',   \n",
    "    'Process Recipe',\n",
    "    'Dose',\n",
    "    'Trim Factor',\n",
    "    'Recipe Energy',\n",
    "    'Recipe Beam Current',\n",
    "    'Implant Species',\n",
    "    'Ion charge',\n",
    "    'E.S. Pressure Comp.',\n",
    "    'B.L. Pressure Comp.',\n",
    "    'Implant Start Prs.',\n",
    "    'Implant Stop Prs.',\n",
    "    'Implant Min. Prs.',\n",
    "    'Tilt angle',\n",
    "    'Twist angle',\n",
    "    'Flat/Notch angle',\n",
    "    'Percent complete',\n",
    "    'Recovery time']\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "     with open('gsd_config_02.txt') as gsd_config_02:\n",
    "         gsd_config_02 = gsd_config_02.read()\n",
    "         print('gsd_config_02.txt file was found. Loading custom capture settings.')\n",
    "         variables_table = gsd_config_02.split('\\n')\n",
    "         variables_table = [i.strip() for i in variables_table]\n",
    "\n",
    "except:\n",
    "    \n",
    "    print('No config file was found. Loading default capture settings.')\n",
    "               \n",
    "\n",
    "    variables_table = ['Total energy       (keV)',\n",
    "    'AMU',\n",
    "    'Beam current       (A)',\n",
    "    'Beam current noise (A)',\n",
    "    'Preset Scans',\n",
    "    'Source Pressure    (Torr)',\n",
    "    'Beamline Pressure  (Torr)',\n",
    "    'Chamber Pressure   (Torr)',\n",
    "    'Linac Pressure     (Torr)',\n",
    "    'Gauge Ratio IG2/IG3',\n",
    "    'Arc Current        (Amps)',\n",
    "    'Arc Voltage        (Volts)',\n",
    "    'Filament Current   (Amps)',\n",
    "    'Cathode Voltage    (Volts)',\n",
    "    'Cathode Current    (Amps)',\n",
    "    'Extraction Current (mA)',\n",
    "    'Extraction Voltage (kV)',\n",
    "    'Vap #1 Oven Temp   (DegC)',\n",
    "    'Vap #1 Heater Temp (DegC)',\n",
    "    'Vap #2 Oven Temp   (DegC)',\n",
    "    'Vap #2 Heater Temp (DegC)',\n",
    "    'Gas #1 MFC         (sccm)',\n",
    "    'Gas #2 MFC         (sccm)',\n",
    "    'Gas #3 MFC         (sccm)',\n",
    "    'Gas #4 MFC         (sccm)',\n",
    "    'Extr Gap Axis',\n",
    "    'Extr Suppress I    (mA)',\n",
    "    'Extr Suppress V    (kV)',\n",
    "    'Extr Suppress I-2  (mA)',\n",
    "    'Extr Suppress V-2  (kV)',\n",
    "    'Source Injection Gas',\n",
    "    'Source Injection Gas Flow',\n",
    "    'Variable Rslv Aperture (mm)',\n",
    "    'Source Magnet I    (Amps)',\n",
    "    'Analyzer Magnet I  (Amps)',\n",
    "    'AMU Hall Probe     (Gauss)',\n",
    "    'Pl.Sh. Gas Flow MFC(sccm)',\n",
    "    'Pl.Sh. Extr Voltage(V)',\n",
    "    'Pl.Sh. Extr Current(mA)',\n",
    "    'Pl.Sh. Arc Voltage (V)',\n",
    "    'Pl.Sh. Arc Current (A)',\n",
    "    'Pl.Sh. Fil Voltage (V)',\n",
    "    'Pl.Sh. Fil Current (A)',\n",
    "    'Pl.Sh. Fil Power   (W)',\n",
    "    'Pl.Sh. Bias Aper Voltage(kV)',\n",
    "    'Pl.Sh. Bias Aper Current(mA)',\n",
    "    'Disk Current       (mA)',\n",
    "    'Charge Mon Pos Peak(volts)',\n",
    "    'Charge Mon Neg Peak(volts)',\n",
    "    'Tilt Angle         (degrees)',\n",
    "    'Twist Angle        (degrees)',\n",
    "    'HYT Particle Counts',\n",
    "    'HYT Stray Light',\n",
    "    'HYT Laser Current  (mA)',\n",
    "    'Beam Height (mm)',\n",
    "    'Beam Height Offset (mm)',\n",
    "    'Gas Bottle 1 pres   (kPa)',\n",
    "    'Gas Deliver 2 pres  (kPa)',\n",
    "    'Gas Deliver 3 pres  (kPa)',\n",
    "    'Gas Deliver 4 pres  (kPa)',\n",
    "    'FOM K-factor     (1/Torr)',\n",
    "    'FOM Intercept        (mA)',\n",
    "    'FOM Max Pressure   (Torr)',\n",
    "    'FOM Min Pressure   (Torr)',\n",
    "    'FOM Total Points',\n",
    "    'Estimated Time     (HHMMSS)',\n",
    "    'Actual Time        (HHMMSS)',\n",
    "    'Actual/Estimated Time',\n",
    "    'Interruptions']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User interface\n",
    "The following sequence will trigger a list of user input requests, this is to collect the location of the IDL files and the desired output fine name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define user input request functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TriggerPresentation():\n",
    "    \n",
    "    '''\n",
    "    Clears the console and prints a program header/presentation.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    presentation = '''\n",
    "     __ __ _        _  __ _____    __    _  _  _  __ __ _ \n",
    "    /__(_ | \\   |  / \\/__|_  | |  |_    |_)|_||_)(_ |_ |_)\n",
    "    \\_|__)|_/   |__\\_/\\_||  _|_|__|__   |  | || \\__)|__| |\n",
    "                                                  \n",
    "    '''\n",
    "\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')  \n",
    "\n",
    "    print(presentation)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AskForDirectory():\n",
    "    \n",
    "    '''\n",
    "    Triggers a user input collection event and validates whether it is a valid directory.\n",
    "    Then returns the collected directory path and the list of files contained in that directory.\n",
    "    \n",
    "    '''\n",
    "    user_filepath = None\n",
    "\n",
    "    while user_filepath not in ['none', '']:  \n",
    "        \n",
    "        user_filepath = input('Please enter a file directory containing GSD logfiles or press ENTER to select current working directory: \\nEXAMPLE: ---> C:\\\\Users\\\\Documents\\\\John\\\\gsd_files\\n')\n",
    "    \n",
    "        if user_filepath.lower() == 'none' or user_filepath == None or user_filepath == '' :\n",
    "            gsd_files = os.listdir()\n",
    "        \n",
    "        else:  \n",
    "            try:\n",
    "                user_filepath.replace('\\\\', r'\\\\')\n",
    "                gsd_files = os.listdir(user_filepath)\n",
    "        \n",
    "                break\n",
    "            \n",
    "            except:\n",
    "                print('Current directory not accepted\\nPlease enter a valid directory or \\'None\\' to select current working directory. ')\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "    \n",
    "    # To ensure input directory ends with '\\', in order to concatenate with single files later on:\n",
    "    \n",
    "    if user_filepath != '' and user_filepath[-1] != '\\\\' :\n",
    "        user_filepath = user_filepath + '\\\\'\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return gsd_files, user_filepath\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GsdFilesCleanup(gsd_files, user_filepath):\n",
    "    \n",
    "    '''\n",
    "    Given a list of file names, splits the list filtering into valid and non valid files.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # REMOVE sub-directories out: Keeps only files with extension (IDL files MUST have an extension)\n",
    "    gsd_files = [file for file in gsd_files if list(file)[0] != '.']\n",
    "    gsd_files = [file for file in gsd_files if '.' in list(file)]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Filters non valid_extensions out:\n",
    "    non_valid_ext = ['csv', 'txt', 'py', 'exe', 'ipynb']\n",
    "    \n",
    "    valid_files = [file for file in gsd_files if (str(file).split('.')[1] not in non_valid_ext)]\n",
    "    non_valid_files = [file for file in gsd_files if (str(file).split('.')[1] in non_valid_ext)]\n",
    "    \n",
    "    \n",
    "    if len(valid_files) > 0:\n",
    "        for file in valid_files:\n",
    "            print(file)  \n",
    "        print('\\n',len(valid_files), ' IDL files have been found.', '\\n')\n",
    "        \n",
    "    else:\n",
    "        print('\\n','No valid IDL files found in directory.', '\\n')\n",
    "\n",
    "\n",
    "    if len(non_valid_files) > 0:\n",
    "        \n",
    "        for file in non_valid_files:\n",
    "            print(file)\n",
    "            \n",
    "        print('\\n',len(non_valid_files), ' non-IDL files dismissed: ', '\\n')\n",
    "    \n",
    "    \n",
    "    return valid_files, non_valid_files\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AskForOutputFile(non_valid_files):\n",
    "\n",
    "    '''\n",
    "    Asks for an output file name that will later be user to generate a csv with generated dataframe.\n",
    "    Validates that the input name does not exists in the current directory.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        List of non-idl files contained in the target directory\n",
    "        \n",
    "    Returns\n",
    "    \n",
    "        Validated output file name, with a .csv extension\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    non_valid_chars = list(r'?!.%@\\#%&{}\\'\"<>*/$:+=|')\n",
    "    validation = False\n",
    "    \n",
    "    while not validation:\n",
    "    \n",
    "        user_output = input('\\nPlease enter an output .csv file name (without extensions):\\nEXAMPLE: ---> \\'output2\\' will produce \\'output2.csv\\'\\n')\n",
    "        \n",
    "        if user_output+'.csv' in non_valid_files:\n",
    "            print('\\nOutput file already exists in current directory. ')\n",
    "            validation = False\n",
    "        \n",
    "        elif len(set(list(user_output)).intersection(non_valid_chars))>0:\n",
    "            print('\\nOutput file contains invalid characters. ')\n",
    "            validation = False\n",
    "            \n",
    "        else:\n",
    "            validation = True\n",
    "\n",
    "    \n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "    print('\\nOutput file name accepted\\n')\n",
    "    \n",
    "    return str(user_output)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProceedConfirmation():\n",
    "\n",
    "    proceed_answer = 'a'\n",
    "    \n",
    "    while proceed_answer != 'y' or proceed_answer != 'n':\n",
    "        proceed_answer = input('Proceed with extraction? (y/n): ')\n",
    "        \n",
    "        try:\n",
    "            proceed_answer.lower()\n",
    "        except:\n",
    "            print('Invalid answer. Please answer yes or no (y/n): ')\n",
    "            continue\n",
    "    \n",
    "        if proceed_answer in ['y', 'Y']:\n",
    "            break\n",
    "        elif proceed_answer in ['n', 'N']:\n",
    "            print('Extraction aborted')\n",
    "            time.sleep(1)\n",
    "            sys.exit()\n",
    "        else:\n",
    "            print('Please answer yes or no (y/n)')\n",
    "            continue\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parser functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define IDL file parser function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsd_extract(gsd_file, user_filepath):\n",
    "\n",
    "    \n",
    "    '''\n",
    "    GSD IDL Text file parser that converts a IDL text file into a python dictionary.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        gsd_file: The NAME of the IDL text file we wish to parse.\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        run_dict: A python dictionary containing the captured information.\n",
    "    \n",
    "    '''\n",
    "    run_dict = {}\n",
    "    \n",
    "    filepath = user_filepath + gsd_file\n",
    "    \n",
    "    with open(filepath, mode ='r') as gsd_run:\n",
    "    \n",
    "        gsd_run = gsd_run.read()\n",
    "        \n",
    "        \n",
    "        # IDL NUMBER COLLECTION\n",
    "        \n",
    "        run_dict['IDL'] = float(gsd_file)\n",
    "\n",
    "\n",
    "\n",
    "        # CAPTURE HEADER INFO: MATERIAL TRACKING INFO\n",
    "        \n",
    "        material_tracking_chunk_regex = r'(Material Tracking.*)Parameter [ ]*#1 Avg'\n",
    "        material_tracking_chunk = re.findall(material_tracking_chunk_regex , gsd_run, re.DOTALL )\n",
    "                              \n",
    "        # DOESN'T LOOK FOR DUMMIES\n",
    "        \n",
    "        mtc_regex = r'(Material I.D.)[^\\n]*(Cassette Slots) \\n[ \\-]*\\n([+\\w\\d\\. \\-]+)[ ]+Port [\\d] :[ ]+([\\d ]+)\\n'        \n",
    "        \n",
    "        mtc_match = re.findall(mtc_regex , material_tracking_chunk[0], re.DOTALL )\n",
    "        mtc_match = mtc_match[0] # match is a list containing a tuple, only want the inside tuple\n",
    "                \n",
    "        # Write captures into dictionary\n",
    "        run_dict[mtc_match[0]] = mtc_match[2]\n",
    "        run_dict[mtc_match[1]] = mtc_match[3]\n",
    "        \n",
    "        \n",
    "        # DUMMIES \n",
    "        \n",
    "        mtc_dummies_regex = r'(DUMMY WAFERS)[ ]+:[ ]*([\\d ]*)\\n'\n",
    "        \n",
    "        try:\n",
    "            mtc_match_dummies = re.findall(mtc_dummies_regex, material_tracking_chunk[0], re.DOTALL)\n",
    "            run_dict['DUMMY WAFERS'] = mtc_match_dummies[0][1]\n",
    "        except:\n",
    "            run_dict['DUMMY WAFERS'] = 'NO DUMMIES'\n",
    "\n",
    "\n",
    "        \n",
    "        # RUN TYPE\n",
    "        \n",
    "        run_type_regex = r'[ ]+([\\w ]+)[ ]Implant Summary'\n",
    "        try:\n",
    "            run_type_match = re.findall(run_type_regex , gsd_run, re.DOTALL )[0]\n",
    "        except:\n",
    "            run_type_match = ''\n",
    "        \n",
    "        if run_type_match == 'Aborted':\n",
    "            run_dict['RUN TYPE'] = 'ABORTED'\n",
    "        elif run_type_match == 'Abt Rec':\n",
    "            run_dict['RUN TYPE'] = 'RECOVERY'\n",
    "        else:\n",
    "            run_dict['RUN TYPE'] = 'NORMAL'\n",
    "        \n",
    "        \n",
    "        \n",
    "        # VARIABLES\n",
    "\n",
    "        single_variable_chunk_regex = r'(Implant Summary.*Flat/Notch angle[^\\n]*\\n)'\n",
    "        single_variable_chunk = re.findall(single_variable_chunk_regex , gsd_run, re.DOTALL )\n",
    "        \n",
    "        for i in variables:\n",
    "              \n",
    "            regex_string = str(i).strip() + '[ ]*' + ':' + r'[ ]*([\\d\\w\\.e+:_\\-]*)'\n",
    "            match = re.findall(regex_string, single_variable_chunk[0], re.DOTALL)\n",
    "            \n",
    "            try:\n",
    "                run_dict[i.strip()] = match[0]\n",
    "            except:\n",
    "                run_dict[i.strip()] = 'NO MATCH'\n",
    "            \n",
    "        \n",
    "        \n",
    "        # VARIABLES TABLE    \n",
    "        \n",
    "        variables_table_chunk_regex = r'(Parameter.*Interruptions[^\\n]*\\n)'\n",
    "        variables_table_chunk = re.findall(variables_table_chunk_regex , gsd_run, re.DOTALL )    \n",
    "        \n",
    "        \n",
    "        for i in variables_table:\n",
    "            \n",
    "            regex_string_table = str(i).strip().replace('(', '\\(').replace(')', '\\)') + r'[ ]*([\\-+:\\.\\d\\w]*)[ ]*([\\-+:\\.\\d\\w]*)[ ]*([\\-+:\\.\\d\\w]*)[ ]*([\\-+:\\.\\d\\w]*)'\n",
    "            \n",
    "            match = re.findall(regex_string_table, variables_table_chunk[0], re.DOTALL)\n",
    "            \n",
    "            \n",
    "            # The above code is intended to generate match lists of 2 elements\n",
    "            # Accidental captures could create duplicates (generate match lists of 4 elements instead of 2)\n",
    "            # Below elif block considers accidental duplicated capture case and selects first of each [0] and [2]\n",
    "            \n",
    "            \n",
    "            # Expected case (first match[0] contains 25 and 50%, match[1] contains 75 and 100%)\n",
    "            if len(match) == 2:\n",
    "                run_dict[i.strip() + ' 25% mean'] = match[0][0]\n",
    "                run_dict[i.strip() + ' 25% std'] = match[0][1]\n",
    "                    \n",
    "                run_dict[i.strip() + ' 50% mean'] = match[0][2]\n",
    "                run_dict[i.strip() + ' 50% std'] = match[0][3]\n",
    "                    \n",
    "                run_dict[i.strip() + ' 75% mean'] = match[1][0]\n",
    "                run_dict[i.strip() + ' 75% std'] = match[1][1]\n",
    "                    \n",
    "                run_dict[i.strip() + ' 100% mean'] = match[1][2]\n",
    "                run_dict[i.strip() + ' 100% std'] = match[1][3]\n",
    "                \n",
    "            # Elif block dismisses duplicated captures (selects [0] and [2] hence avoiding duplicates in [1] and [3])   \n",
    "            elif len(match) == 4:\n",
    "                run_dict[i.strip() + ' 25% mean'] = match[0][0]\n",
    "                run_dict[i.strip() + ' 25% std'] = match[0][1]\n",
    "                    \n",
    "                run_dict[i.strip() + ' 50% mean'] = match[0][2]\n",
    "                run_dict[i.strip() + ' 50% std'] = match[0][3]\n",
    "                    \n",
    "                run_dict[i.strip() + ' 75% mean'] = match[2][0]\n",
    "                run_dict[i.strip() + ' 75% std'] = match[2][1]\n",
    "                    \n",
    "                run_dict[i.strip() + ' 100% mean'] = match[2][2]\n",
    "                run_dict[i.strip() + ' 100% std'] = match[2][3]\n",
    "            \n",
    "                \n",
    "    return run_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gather all files to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GsdCollectionBuilder(valid_files):\n",
    "\n",
    "    run_collection = []\n",
    "    failed_extract = []\n",
    "\n",
    "    for filename in tqdm(valid_files):\n",
    "        \n",
    "        try:\n",
    "            run_collection.append(gsd_extract(filename, user_filepath))\n",
    "\n",
    "        except:\n",
    "            failed_extract.append(i)\n",
    "    \n",
    "    print('\\nEXTRACTION COMPLETED\\n')\n",
    "    print('\\nGenerating output files ...\\n')\n",
    "    \n",
    "    return run_collection, failed_extract\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GsdDataFrameBuilder(run_collection):\n",
    "  \n",
    "    d = {}\n",
    "\n",
    "    if len(run_collection)>0:\n",
    "\n",
    "        for k in run_collection[0].keys():\n",
    "          d[k] = list(d[k] for d in run_collection)\n",
    "    \n",
    "        return pd.DataFrame(data=d)\n",
    "\n",
    "    else:\n",
    "        print('\\n None of the IDL files could be extracted. \\n')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalSummary(failed_extract):\n",
    "    \n",
    "    if len(failed_extract) > 0:\n",
    "        print('\\nThe parser failed to extract ', str(len(failed_extract)), ' files.')\n",
    "        print('FAILED to extract the following IDL files: ', '\\n')\n",
    "    \n",
    "        for i in failed_extract:\n",
    "            print(i)\n",
    "        \n",
    "        failed_output_name = user_output + '_FAILED' + '.txt'\n",
    "    \n",
    "        with open(failed_output_name, \"w\") as failed_output:\n",
    "            failed_output.write(str(failed_extract))\n",
    "            \n",
    "    else:\n",
    "        print('\\nAll IDL files were successfully extracted.\\n')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExitSequence():\n",
    "    \n",
    "    exit_opt = True\n",
    "    \n",
    "    while exit_opt:\n",
    "        \n",
    "        exit_ans = input('\\nProgram completed. Type \\'end\\' to exit: ')\n",
    "        exit_ans = exit_ans.lower()\n",
    "    \n",
    "        if exit_ans == 'end':\n",
    "            exit_opt = False\n",
    "        else:\n",
    "            exit_opt = True  \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     __ __ _        _  __ _____    __    _  _  _  __ __ _ \n",
      "    /__(_ | \\   |  / \\/__|_  | |  |_    |_)|_||_)(_ |_ |_)\n",
      "    \\_|__)|_/   |__\\_/\\_||  _|_|__|__   |  | || \\__)|__| |\n",
      "                                                  \n",
      "    \n",
      "Please enter a file directory containing GSD logfiles or press ENTER to select current working directory: \n",
      "EXAMPLE: ---> C:\\Users\\Documents\\John\\gsd_files\n",
      "\n",
      "201117.185708\n",
      "201117.190236\n",
      "201117.190921\n",
      "201117.191505\n",
      "201119.115732\n",
      "201119.120301\n",
      "201121.064905\n",
      "201121.065527\n",
      "\n",
      " 8  IDL files have been found. \n",
      "\n",
      "gsd_parser_v202.ipynb\n",
      "gsd_parser_v202.py\n",
      "gsd_regex_v202_original.py\n",
      "test.csv\n",
      "test03.csv\n",
      "test04.csv\n",
      "test05.csv\n",
      "trick.csv\n",
      "\n",
      " 8  non-IDL files dismissed:  \n",
      "\n",
      "\n",
      "Please enter an output .csv file name (without extensions):\n",
      "EXAMPLE: ---> 'output2' will produce 'output2.csv'\n",
      "test06\n",
      "\n",
      "Output file name accepted\n",
      "\n",
      "Proceed with extraction? (y/n): y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 25.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXTRACTION COMPLETED\n",
      "\n",
      "\n",
      "Generating output files ...\n",
      "\n",
      "\n",
      "All IDL files were successfully extracted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TriggerPresentation()\n",
    "\n",
    "\n",
    "# User interface - collect user info\n",
    "\n",
    "gsd_files, user_filepath = AskForDirectory()\n",
    "\n",
    "valid_files, non_valid_files = GsdFilesCleanup(gsd_files, user_filepath)\n",
    "\n",
    "output_file = AskForOutputFile(non_valid_files)\n",
    "\n",
    "ProceedConfirmation()\n",
    "\n",
    "\n",
    "# Start parsing\n",
    "\n",
    "run_collection, failed_extract = GsdCollectionBuilder(valid_files)\n",
    "\n",
    "gsd_df = GsdDataFrameBuilder(run_collection)\n",
    "gsd_df.to_csv(user_filepath + output_file, mode = 'a')\n",
    "\n",
    "FinalSummary(failed_extract)\n",
    "\n",
    "ExitSequence()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
